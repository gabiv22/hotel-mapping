{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9cfbb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import Levenshtein\n",
    "import itertools\n",
    "from fuzzywuzzy import fuzz\n",
    "import fasttext\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from fastDamerauLevenshtein import damerauLevenshtein"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f475e736",
   "metadata": {},
   "source": [
    "TODO: use mapping between cities from examples dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdc3d545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499, 14)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partner1_df = pd.read_excel(\"Example.xlsx\", \"Partner1\")\n",
    "partner2_df = pd.read_excel(\"Example.xlsx\", \"Partner2\")\n",
    "examples_df = pd.read_excel(\"Example.xlsx\", \"examples\")\n",
    "\n",
    "# rename columns \n",
    "partner1_df.columns = ['key', 'hotel_name', 'city_name', 'country_code','hotel_address', 'star_rating', 'postal_code']\n",
    "partner2_df.columns = ['key', 'hotel_name', 'city_name', 'country_code','hotel_address', 'star_rating', 'postal_code']\n",
    "\n",
    "examples_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71d3b183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(key                 0\n",
       " hotel_name          0\n",
       " city_name           0\n",
       " country_code        5\n",
       " hotel_address       1\n",
       " star_rating         0\n",
       " postal_code      1750\n",
       " dtype: int64,\n",
       " key                0\n",
       " hotel_name         0\n",
       " city_name          0\n",
       " country_code       5\n",
       " hotel_address      1\n",
       " star_rating        0\n",
       " postal_code      664\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "partner1_df.isna().sum(), partner2_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ae3afd",
   "metadata": {},
   "source": [
    "since only a few \"country_code\" are missing, it really doesn't make any sense to fill them. but if we want to try to fill them I thought about using the known mapping between city - country_code. (the commented code) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3559d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check if can infer country based on city\n",
    "# all_known_countries_and_cities_df = pd.concat([partner1_df.loc[:,['city_name', 'country_code']],\n",
    "#                                               partner2_df.loc[:,['p2.city_name', 'p2.country_code']],\n",
    "#                                               examples_df.loc[:,['p1.city_name', 'p1.country_code']].rename(columns={'p1.city_name': 'city_name', 'p1.country_code': 'country_code'}),\n",
    "#                                               examples_df.loc[:,['p2.city_name', 'p2.country_code']].rename(columns={'p2.city_name': 'city_name', 'p2.country_code': 'country_code'})])\n",
    "# unique_countries_per_city = all_known_countries_and_cities_df.groupby('city_name')['country_code'].apply(lambda x: np.unique(x))\n",
    "\n",
    "\n",
    "# # try to fill \"country_code\" nans using city name --DOESNT REALLY WORK since cities are new to us\n",
    "# partner1_df['p1.country_code1'] = partner1_df.apply(\n",
    "#     lambda row: unique_countries_per_city.loc[row['p1.city_name']][0] if len(unique_countries_per_city.loc[row['p1.city_name']]) == 1 else row['p1.country_code'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f26158d",
   "metadata": {},
   "source": [
    "I don't see anything interesting to learn in star_rating, although maybe we can check by spliting into countries to learn a new relation???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7e5ecc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# judging by examples_df - star_rating is not super reliable\n",
    "star_rating_df = examples_df.loc[examples_df['p1.star_rating'] != examples_df['p2.star_rating']].loc[:,['p1.star_rating', \"p2.star_rating\", \"p1.country_code\"]]\n",
    "star_rating_df = star_rating_df.dropna()\n",
    "star_rating_df[\"diff_rating\"] = star_rating_df[\"p1.star_rating\"] - star_rating_df[\"p2.star_rating\"]\n",
    "star_rating_df[\"diff_rating\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "id": "bb4e1608",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#star_rating_df.groupby('p1.country_code').diff_rating.apply(lambda x: x.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b26ee7",
   "metadata": {},
   "source": [
    "found a website online with mapping between country code and name. will use to strip country name from address/ hotel name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82ead7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "page = requests.get(\"https://www.iban.com/country-codes\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "#country_name, country_id = [], []\n",
    "country2id = {}\n",
    "for tr in soup.find_all('tr')[2:]:\n",
    "    tds = tr.find_all('td')\n",
    "    #country_name.append(tds[0].text) \n",
    "    #country_id.append(tds[1].text)\n",
    "    country2id[tds[1].text] = tds[0].text\n",
    "    \n",
    "country2id['XK'] = 'Kosovo'\n",
    "country2id['LA'] = 'laos'\n",
    "    \n",
    "#country2id = pd.DataFrame.from_dict({\"country_name\": country_name, \"country_id\": country_id})\n",
    "#country2id.head()\n",
    "\n",
    "# check that \"country_id\" is a unique identifier\n",
    "print(len(np.unique(list(country2id.values())))/len(country2id.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed0652df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "818                     NaN\n",
       "996                    2117\n",
       "2324                   2505\n",
       "2341    2008-02-02 00:00:00\n",
       "3014    2029-02-07 00:00:00\n",
       "3449                    171\n",
       "3537                   4169\n",
       "5270                   4027\n",
       "7079                    300\n",
       "8234    2001-01-05 00:00:00\n",
       "8406    2016-02-18 00:00:00\n",
       "9301    2012-02-12 00:00:00\n",
       "Name: hotel_address, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if all addresses are strings\n",
    "partner1_df['hotel_address'].loc[partner1_df['hotel_address'].apply(type) != type(partner1_df['hotel_address'][0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eceaa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some addresses are actually dates so just convert to na \n",
    "import time\n",
    "def isTimeFormat(s):\n",
    "    try:\n",
    "        time.strptime(str(s), '%Y-%m-%d %H:%M:%S')\n",
    "        return ''\n",
    "    except:\n",
    "        return str(s)\n",
    "partner1_df['hotel_address'] = partner1_df['hotel_address'].apply(isTimeFormat)\n",
    "partner2_df['hotel_address'] = partner2_df['hotel_address'].apply(isTimeFormat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec853e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase \n",
    "examples_df['p1.city_name'] = examples_df['p1.city_name'].str.lower()\n",
    "examples_df['p2.city_name'] = examples_df['p2.city_name'].str.lower()\n",
    "examples_df['p1.hotel_address'] = examples_df['p1.hotel_address'].str.lower()\n",
    "examples_df['p2.hotel_address'] = examples_df['p2.hotel_address'].str.lower()\n",
    "\n",
    "partner1_df['hotel_address'] = partner1_df['hotel_address'].str.lower()\n",
    "partner2_df['hotel_address'] = partner2_df['hotel_address'].str.lower()\n",
    "partner1_df['city_name'] = partner1_df['city_name'].str.lower()\n",
    "partner2_df['city_name'] = partner2_df['city_name'].str.lower()\n",
    "partner1_df['hotel_name'] = partner1_df['hotel_name'].str.lower()\n",
    "partner2_df['hotel_name'] = partner2_df['hotel_name'].str.lower()\n",
    "\n",
    "# check if our dataset \"country_id\" matches all with scraped \"country_id\"s\n",
    "partner1_df['country_name'] = partner1_df['country_code'].apply(lambda c: country2id[c].lower() if not pd.isnull(c) else c)\n",
    "partner2_df['country_name'] = partner2_df['country_code'].apply(lambda c: country2id[c].lower() if not pd.isnull(c) else c)\n",
    "\n",
    "examples_df['p1.country_name'] = examples_df['p1.country_code'].apply(lambda c: country2id[c].lower() if not pd.isnull(c) else c)\n",
    "examples_df['p2.country_name'] = examples_df['p2.country_code'].apply(lambda c: country2id[c].lower() if not pd.isnull(c) else c)\n",
    "\n",
    "\n",
    "#partner1_df['p1.country_code'] = partner1_df['p1.country_code'].apply(str)\n",
    "\n",
    "# remove \"-\" or spaces from postal_code string\n",
    "partner1_df['clean_postal_code'] = partner1_df['postal_code'].apply(lambda s: list(filter(len, re.split('-| ',str(s)))))\n",
    "partner2_df['clean_postal_code'] = partner2_df['postal_code'].apply(lambda s: list(filter(len, re.split('-| ',str(s)))))\n",
    "examples_df['p1.clean_postal_code'] = examples_df['p1.postal_code'].apply(lambda s: list(filter(len, re.split('-| ',str(s)))))\n",
    "examples_df['p2.clean_postal_code'] = examples_df['p2.postal_code'].apply(lambda s: list(filter(len, re.split('-| ',str(s)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33a2b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "partner1_df.fillna('', inplace=True)\n",
    "partner2_df.fillna('', inplace=True)\n",
    "examples_df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7a4b84d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(partner1_df.loc[partner1_df['postal_code'].apply(type) != partner1_df['postal_code'].apply(type)[0]]['postal_code'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1350811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4554"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets remove all mentions of cities/ country id's from addresses and hotel names:\n",
    "all_cities = partner1_df['city_name'].apply(\n",
    "    lambda s: [part.strip() for part in re.split('[\\(\\)]', s) if part.strip()]).tolist() + partner2_df['city_name'].apply(\n",
    "    lambda s: [part.strip() for part in re.split('[\\(\\)]', s) if part.strip()]).tolist() + examples_df['p1.city_name'].apply(\n",
    "    lambda s: [part.strip() for part in re.split('[\\(\\)]', s) if part.strip()]).tolist() + examples_df['p2.city_name'].apply(\n",
    "    lambda s: [part.strip() for part in re.split('[\\(\\)]', s) if part.strip()]).tolist()\n",
    "    \n",
    "all_cities = [re.sub(r'[^\\w\\s]',' ',str(c)) for c_l in all_cities for c in c_l]\n",
    "\n",
    "all_countries = partner1_df['country_code'].apply(\n",
    "    lambda s: s.split()).tolist() +partner2_df['country_code'].apply(\n",
    "    lambda s: s.split()).tolist() + examples_df['p1.country_code'].apply(\n",
    "    lambda s: s.split()).tolist() + examples_df['p2.country_code'].apply(\n",
    "    lambda s: s.split()).tolist()\n",
    "all_countries = [re.sub(r'[^\\w\\s]',' ',str(c)) for c_l in all_countries for c in c_l ]\n",
    "\n",
    "\n",
    "countries_and_cities_unique = list(np.unique(all_cities + all_countries))\n",
    "countries_and_cities_unique = [c for c in countries_and_cities_unique if len(c)>1]\n",
    "len(countries_and_cities_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "796f1482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "def remove_from_string(input_string: str, words_to_remove: list):\n",
    "    try:\n",
    "        input_string = re.sub(r'[^\\w\\s]',' ',str(input_string))\n",
    "        input_string_words = input_string.split()\n",
    "    except:\n",
    "        pdb.set_trace()\n",
    "    return ' '.join([word.lower() for word in input_string_words if word.lower() not in words_to_remove])\n",
    "\n",
    "# remove city and country name from address\n",
    "address_redundent_words = ['dr', 'drive', 'city', 'street', 'st', 'str', 'streets', 'road', 'blvd', 'roads', 'rd', 'district', 'boulevard', 'via']\n",
    "\n",
    "partner1_df['clean_address'] = partner1_df.apply(\n",
    "    lambda row: remove_from_string(row['hotel_address'], \n",
    "                                   address_redundent_words + countries_and_cities_unique), axis=1)\n",
    "\n",
    "partner2_df['clean_address'] = partner2_df.apply(\n",
    "    lambda row: remove_from_string(row['hotel_address'], \n",
    "                                   address_redundent_words + countries_and_cities_unique), axis=1)\n",
    "\n",
    "examples_df['p1.clean_address'] = examples_df.apply(\n",
    "    lambda row: remove_from_string(row['p1.hotel_address'], \n",
    "                                   address_redundent_words + countries_and_cities_unique), axis=1)\n",
    "\n",
    "examples_df['p2.clean_address'] = examples_df.apply(\n",
    "    lambda row: remove_from_string(row['p2.hotel_address'], \n",
    "                                   address_redundent_words + countries_and_cities_unique), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1216105d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of known easy keywords from \"hotel_name\" - NOT USED!\n",
    "hotel_name_redundent_words = ['hostel', 'guesthouse','resort', 'resorts', 'suites', 'suite', 'apartment', 'apartments', 'inn', 'hotel', 'hotels', 'and', '&']\n",
    "\n",
    "# remove city and country name and keywords from \"hotel_name\":\n",
    "partner1_df['clean_hotel_name'] = partner1_df.apply(\n",
    "    lambda row: remove_from_string(row['hotel_name'], \n",
    "                                   countries_and_cities_unique), axis=1)\n",
    "\n",
    "partner2_df['clean_hotel_name'] = partner2_df.apply(\n",
    "    lambda row: remove_from_string(row['hotel_name'], \n",
    "                                   countries_and_cities_unique), axis=1)\n",
    "\n",
    "examples_df['p1.clean_hotel_name'] = examples_df.apply(\n",
    "    lambda row: remove_from_string(row['p1.hotel_name'], \n",
    "                                   countries_and_cities_unique), axis=1)\n",
    "\n",
    "examples_df['p2.clean_hotel_name'] = examples_df.apply(\n",
    "    lambda row: remove_from_string(row['p2.hotel_name'], \n",
    "                                   countries_and_cities_unique), axis=1)\n",
    "\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "def remove_longest_substring_from_first(s1, s2):\n",
    "    match = SequenceMatcher(None, s1, s2).find_longest_match()\n",
    "    matched_str = s1[match.a:match.a + match.size]\n",
    "    matched_str = \" \".join(m for m in matched_str.split() if m in s1.split() or m in s2.split())\n",
    "    if len(matched_str) > 3:\n",
    "    # return s1[:match.a]+ s1[match.a + match.size:]\n",
    "        return s1.replace(matched_str, \"\").strip()\n",
    "    return s1\n",
    "\n",
    "\n",
    "\n",
    "# remove address from hotel name:\n",
    "partner1_df['clean_hotel_name'] = partner1_df.apply(\n",
    "    lambda row: remove_longest_substring_from_first(row['clean_hotel_name'], row['clean_address']), axis=1)\n",
    "\n",
    "partner2_df['clean_hotel_name'] = partner2_df.apply(\n",
    "    lambda row: remove_longest_substring_from_first(row['clean_hotel_name'], row['clean_address']), axis=1)\n",
    "\n",
    "examples_df['p1.clean_hotel_name'] = examples_df.apply(\n",
    "    lambda row: remove_longest_substring_from_first(row['p1.clean_hotel_name'], row['p1.clean_address']), axis=1)\n",
    "\n",
    "examples_df['p2.clean_hotel_name'] = examples_df.apply(\n",
    "    lambda row: remove_longest_substring_from_first(row['p2.clean_hotel_name'], row['p2.clean_address']), axis=1)\n",
    "\n",
    "\n",
    "# remove redundent words list from \"hotel_name\":\n",
    "# partner1_df['clean_hotel_name_redundent'] = partner1_df.apply(\n",
    "#     lambda row: remove_from_string(row['clean_hotel_name'], \n",
    "#                                    hotel_name_redundent_words), axis=1)\n",
    "\n",
    "# partner2_df['clean_hotel_name_redundent'] = partner2_df.apply(\n",
    "#     lambda row: remove_from_string(row['clean_hotel_name'], \n",
    "#                                    hotel_name_redundent_words), axis=1)\n",
    "\n",
    "# examples_df['p1.clean_hotel_name_redundent'] = examples_df.apply(\n",
    "#     lambda row: remove_from_string(row['p1.clean_hotel_name'], \n",
    "#                                    hotel_name_redundent_words ), axis=1)\n",
    "\n",
    "# examples_df['p2.clean_hotel_name_redundent'] = examples_df.apply(\n",
    "#     lambda row: remove_from_string(row['p2.clean_hotel_name'], \n",
    "#                                    hotel_name_redundent_words ), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e72893ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key                                   F370487187D23B44E5C73DB8BA44220D\n",
       "hotel_name                                    j.a. villa pattaya hotel\n",
       "city_name                                                      pattaya\n",
       "country_code                                                        TH\n",
       "hotel_address        3/241 moo 6, pattaya 3rd road, naklua, banglamung\n",
       "star_rating                                                        4.0\n",
       "postal_code                                                      20150\n",
       "country_name                                                  thailand\n",
       "clean_postal_code                                              [20150]\n",
       "clean_address                        3 241 moo 6 3rd naklua banglamung\n",
       "clean_hotel_name                                       j a villa hotel\n",
       "Name: 931, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partner1_df.loc[931,:]#['p1.hotel_name'].sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ea9a0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p1.key                                   074BF1CC1F1C150E080EBB9855D23EAC\n",
       "p1.hotel_name                                       Grand Malioboro Hotel\n",
       "p1.city_name                                                        jambi\n",
       "p1.country_code                                                        ID\n",
       "p1.hotel_address                          jl. iskandar muda no. 168 jambi\n",
       "p1.star_rating                                                        3.0\n",
       "p1.postal_code                                                           \n",
       "p2.key                                   CBEF956F35D16548C939056575C7E0C7\n",
       "p2.hotel_name                                       Grand Malioboro Hotel\n",
       "p2.city_name                                                        jambi\n",
       "p2.country_code                                                        ID\n",
       "p2.hotel_address        jalan iskandar muda no. 168, sei asam, pasar j...\n",
       "p2.star_rating                                                        3.0\n",
       "p2.postal_code                                                      36113\n",
       "p1.country_name                                                 indonesia\n",
       "p2.country_name                                                 indonesia\n",
       "p1.clean_postal_code                                                [nan]\n",
       "p2.clean_postal_code                                              [36113]\n",
       "p1.clean_address                                  jl iskandar muda no 168\n",
       "p2.clean_address                jalan iskandar muda no 168 sei asam pasar\n",
       "p1.clean_hotel_name                                 grand malioboro hotel\n",
       "p2.clean_hotel_name                                 grand malioboro hotel\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_df.loc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f0a20ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for some countries postalcode is useless\n",
    "partner2_df.groupby('country_code').clean_postal_code.apply(lambda x: len(np.unique(x))).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57319433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/76/4rxszdjj23sftmw56f0_fz5h0000gn/T/ipykernel_28070/2977765283.py:3: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  partner2_df.loc[partner2_df.country_code.isin(postal2country.loc[postal2country == 1].index), 'clean_postal_code'] = np.repeat([pd.np.nan], n2)\n",
      "/var/folders/76/4rxszdjj23sftmw56f0_fz5h0000gn/T/ipykernel_28070/2977765283.py:7: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  partner1_df.loc[partner1_df.country_code.isin(postal2country.loc[postal2country == 1].index), 'clean_postal_code'] = np.repeat([pd.np.nan], n1)\n"
     ]
    }
   ],
   "source": [
    "postal2country = partner2_df.groupby('country_code').clean_postal_code.apply(lambda x: len(np.unique(x)))\n",
    "n2 = partner2_df.loc[partner2_df.country_code.isin(postal2country.loc[postal2country == 1].index), 'clean_postal_code'].shape[0]\n",
    "partner2_df.loc[partner2_df.country_code.isin(postal2country.loc[postal2country == 1].index), 'clean_postal_code'] = np.repeat([pd.np.nan], n2)\n",
    "\n",
    "postal2country = partner1_df.groupby('country_code').clean_postal_code.apply(lambda x: len(np.unique(x)))\n",
    "n1 = partner1_df.loc[partner1_df.country_code.isin(postal2country.loc[postal2country == 1].index), 'clean_postal_code'].shape[0]\n",
    "partner1_df.loc[partner1_df.country_code.isin(postal2country.loc[postal2country == 1].index), 'clean_postal_code'] = np.repeat([pd.np.nan], n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89bb5d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_min_postal_dist(r):\n",
    "    min_dist = 999\n",
    "    \n",
    "    perms_p1 = [\"\".join(p) for p in list(itertools.permutations(r['p1.clean_postal_code']))]+r['p1.clean_postal_code']\n",
    "    perms_p2 = [\"\".join(p) for p in list(itertools.permutations(r['p2.clean_postal_code']))]+r['p2.clean_postal_code']\n",
    "    for p1 in perms_p1:\n",
    "        for p2 in perms_p2:\n",
    "            d = damerauLevenshtein(p1.lower(), p2.lower(), similarity=False) / np.min([len(p1), len(p2)])\n",
    "            if d < min_dist:\n",
    "                min_dist = d\n",
    "    return min_dist\n",
    "\n",
    "example_postal_code_df = examples_df.loc[examples_df['p2.clean_postal_code'] != examples_df['p1.clean_postal_code']].loc[:,['p1.clean_postal_code', 'p2.clean_postal_code']]#.sample(100)\n",
    "\n",
    "example_postal_code_df['postal_code_dist'] = example_postal_code_df.apply(\n",
    "    lambda r: get_min_postal_dist(r), axis=1)\n",
    "example_postal_code_df = example_postal_code_df.loc[example_postal_code_df['postal_code_dist'] != np.inf]\n",
    "example_postal_code_df.loc[example_postal_code_df[\"postal_code_dist\"] !=999][\"postal_code_dist\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "3400a664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1.clean_postal_code</th>\n",
       "      <th>p2.clean_postal_code</th>\n",
       "      <th>postal_code_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[nan]</td>\n",
       "      <td>[36113]</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[nan]</td>\n",
       "      <td>[510420]</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[140, 201]</td>\n",
       "      <td>[140, 200]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[528000]</td>\n",
       "      <td>[528061]</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[946]</td>\n",
       "      <td>[964]</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>[263761]</td>\n",
       "      <td>[11221]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>[nan]</td>\n",
       "      <td>[300]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>[82600]</td>\n",
       "      <td>[82000]</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>[730030]</td>\n",
       "      <td>[730000]</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>[410191]</td>\n",
       "      <td>[40191]</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    p1.clean_postal_code p2.clean_postal_code  postal_code_dist\n",
       "0                  [nan]              [36113]          1.666667\n",
       "3                  [nan]             [510420]          2.000000\n",
       "7             [140, 201]           [140, 200]          0.000000\n",
       "12              [528000]             [528061]          0.333333\n",
       "15                 [946]                [964]          0.333333\n",
       "..                   ...                  ...               ...\n",
       "490             [263761]              [11221]          1.000000\n",
       "491                [nan]                [300]          1.000000\n",
       "492              [82600]              [82000]          0.200000\n",
       "494             [730030]             [730000]          0.166667\n",
       "495             [410191]              [40191]          0.200000\n",
       "\n",
       "[142 rows x 3 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_postal_code_df.loc[example_postal_code_df[\"postal_code_dist\"] !=999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0993eaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1.clean_hotel_name</th>\n",
       "      <th>p2.clean_hotel_name</th>\n",
       "      <th>hotel_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7 days inn baiyun yongtai metro 2nd branch</td>\n",
       "      <td>7days inn  yongtai subway station 2nd</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pension flying sumo</td>\n",
       "      <td>flying sumo surf company</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sagala boutique hotel</td>\n",
       "      <td>boutique hotel</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>inn the city business hotel</td>\n",
       "      <td>inn the city hotel</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>khumsuk resort</td>\n",
       "      <td>khamsuk resort</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>atrium hotel and suites</td>\n",
       "      <td>atrium hotel jacuzzi suites</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>hidden paradise by rahi resort</td>\n",
       "      <td>hidden paradise by rahi resorts</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>green coconut resort ecr</td>\n",
       "      <td>green coconut resort</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>7 days inn  road branch</td>\n",
       "      <td>7days inn  road</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>hotel le mireille</td>\n",
       "      <td>le mireille</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            p1.clean_hotel_name  \\\n",
       "3    7 days inn baiyun yongtai metro 2nd branch   \n",
       "5                           pension flying sumo   \n",
       "6                         sagala boutique hotel   \n",
       "10                  inn the city business hotel   \n",
       "11                               khumsuk resort   \n",
       "..                                          ...   \n",
       "484                     atrium hotel and suites   \n",
       "488              hidden paradise by rahi resort   \n",
       "493                    green coconut resort ecr   \n",
       "494                     7 days inn  road branch   \n",
       "498                           hotel le mireille   \n",
       "\n",
       "                       p2.clean_hotel_name  hotel_dist  \n",
       "3    7days inn  yongtai subway station 2nd        0.38  \n",
       "5                 flying sumo surf company        0.41  \n",
       "6                           boutique hotel        0.10  \n",
       "10                      inn the city hotel        0.20  \n",
       "11                          khamsuk resort        0.07  \n",
       "..                                     ...         ...  \n",
       "484            atrium hotel jacuzzi suites        0.18  \n",
       "488        hidden paradise by rahi resorts        0.02  \n",
       "493                   green coconut resort        0.08  \n",
       "494                        7days inn  road        0.20  \n",
       "498                            le mireille        0.10  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def best_fuzz(s1,s2):\n",
    "    max_score = 0\n",
    "    l_s1 = s1.split()\n",
    "    l_s2 = s2.split()\n",
    "    perms_s1 = [\"\".join(l_s1), s1]\n",
    "    perms_s2 = [\"\".join(l_s2), s2]\n",
    "    if s1 in s2 or s2 in s1 and np.min([len(l_s1), len(l_s2)])>1:\n",
    "        max_score=90        \n",
    "    for s1_ in perms_s1:\n",
    "        for s2_ in perms_s2:\n",
    "            score = fuzz.token_sort_ratio(s1_,s2_)\n",
    "            if max_score < score:\n",
    "                max_score = score \n",
    "    return (100 - max_score)/100\n",
    "\n",
    "# doesn't work... will use fuzzywuzzy\n",
    "def fasttext_cosine_sim(s1, s2, model):\n",
    "    \n",
    "    v1 = model.get_sentence_vector(s1).reshape(1, -1)\n",
    "    v2 = model.get_sentence_vector(s1).reshape(1, -1)\n",
    "    return 1 - np.round(cosine_similarity(v1,v2)[0][0], 7)\n",
    "\n",
    "\n",
    "example_hotel_df = examples_df.loc[examples_df['p2.clean_hotel_name'] != examples_df['p1.clean_hotel_name']].loc[:,['p1.clean_hotel_name', 'p2.clean_hotel_name']]#.sample(100)\n",
    "\n",
    "example_hotel_df['hotel_dist'] = example_hotel_df.apply(\n",
    "    lambda r: best_fuzz(r['p1.clean_hotel_name'],r['p2.clean_hotel_name']), axis=1)\n",
    "example_hotel_df.loc[example_hotel_df.hotel_dist > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d0d8a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1.clean_address</th>\n",
       "      <th>p2.clean_address</th>\n",
       "      <th>address_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jl iskandar muda no 168</td>\n",
       "      <td>jalan iskandar muda no 168 sei asam pasar</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>171 moo 1 tambol ngiu ampor wiangpapao chiangrai</td>\n",
       "      <td>171 moo 1 tambol pangiu chiangrai</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>holiday gaura waddo</td>\n",
       "      <td>holiday gaura waddo bardez</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>building 3 no 116 tongtai</td>\n",
       "      <td>no 3 building no 116 tongtai baiyun</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2140 2 machi hama isumi gun</td>\n",
       "      <td>hama 2140 2</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>kirinda sitthulpawwa rottawewa lake</td>\n",
       "      <td>sithulpawwa</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>no 69 yongchang chengguan</td>\n",
       "      <td>no 69 yongchang</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>jl dago golf 3 cigadung raya</td>\n",
       "      <td>jl dago golf no 3 cigadung raya</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>jalan singaraja gilimanuk indonesia</td>\n",
       "      <td>desa sumberkima kecamatan gerokgak kabupaten b...</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>rue davy</td>\n",
       "      <td>24 rue davy</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     p1.clean_address  \\\n",
       "0                             jl iskandar muda no 168   \n",
       "1    171 moo 1 tambol ngiu ampor wiangpapao chiangrai   \n",
       "2                                 holiday gaura waddo   \n",
       "3                           building 3 no 116 tongtai   \n",
       "5                         2140 2 machi hama isumi gun   \n",
       "..                                                ...   \n",
       "492               kirinda sitthulpawwa rottawewa lake   \n",
       "494                         no 69 yongchang chengguan   \n",
       "495                      jl dago golf 3 cigadung raya   \n",
       "497               jalan singaraja gilimanuk indonesia   \n",
       "498                                          rue davy   \n",
       "\n",
       "                                      p2.clean_address  address_dist  \n",
       "0            jalan iskandar muda no 168 sei asam pasar          0.28  \n",
       "1                    171 moo 1 tambol pangiu chiangrai          0.23  \n",
       "2                           holiday gaura waddo bardez          0.10  \n",
       "3                  no 3 building no 116 tongtai baiyun          0.17  \n",
       "5                                          hama 2140 2          0.42  \n",
       "..                                                 ...           ...  \n",
       "492                                        sithulpawwa          0.49  \n",
       "494                                    no 69 yongchang          0.10  \n",
       "495                    jl dago golf no 3 cigadung raya          0.04  \n",
       "497  desa sumberkima kecamatan gerokgak kabupaten b...          0.66  \n",
       "498                                        24 rue davy          0.10  \n",
       "\n",
       "[311 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_adderss_df = examples_df.loc[examples_df['p2.clean_address'] != examples_df['p1.clean_address']].loc[:,['p1.clean_address', 'p2.clean_address']]#.sample(100)\n",
    "\n",
    "example_adderss_df['address_dist'] = example_adderss_df.apply(\n",
    "    lambda r: best_fuzz(r['p1.clean_address'],r['p2.clean_address']), axis=1)\n",
    "example_adderss_df.loc[example_adderss_df.address_dist > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2926ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('hotel names', 0.07995000000000001, 0.6419)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate fuzzywuzzy\n",
    "import random\n",
    "pos = random.sample(range(0, examples_df.shape[0]-1), 200)\n",
    "pos_score = 0\n",
    "for idx in pos:\n",
    "    s1 = examples_df.loc[idx, 'p1.clean_hotel_name']\n",
    "    s2 = examples_df.loc[idx, 'p2.clean_hotel_name']\n",
    "    pos_score += best_fuzz(s1, s2) #, hotel_model)\n",
    "pos_score = pos_score/200\n",
    "\n",
    "neg = random.sample(range(0, examples_df.shape[0]-1), 200)\n",
    "neg_score = 0\n",
    "for idx in neg:\n",
    "    s1 = examples_df.loc[idx,'p1.clean_hotel_name']\n",
    "    s2 = examples_df['p2.clean_hotel_name'].sample(1).values[0]\n",
    "    neg_score += best_fuzz(s1, s2) #, hotel_model)\n",
    "neg_score = neg_score/200\n",
    "\n",
    "\"hotel names\", pos_score, neg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77f68d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('addresses', 0.14235000000000006, 0.7024499999999998)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate fuzzywuzzy\n",
    "import random\n",
    "pos = random.sample(range(0, examples_df.shape[0]-1), 200)\n",
    "pos_score = 0\n",
    "for idx in pos:\n",
    "    s1 = examples_df.loc[idx, 'p1.clean_address']\n",
    "    s2 = examples_df.loc[idx, 'p2.clean_address']\n",
    "    pos_score += best_fuzz(s1, s2) #, hotel_model)\n",
    "pos_score = pos_score/200\n",
    "\n",
    "neg = random.sample(range(0, examples_df.shape[0]-1), 200)\n",
    "neg_score = 0\n",
    "for idx in neg:\n",
    "    s1 = examples_df.loc[idx,'p1.clean_address']\n",
    "    s2 = examples_df['p2.clean_address'].sample(1).values[0]\n",
    "    neg_score += best_fuzz(s1, s2) #, hotel_model)\n",
    "neg_score = neg_score/200\n",
    "\n",
    "\"addresses\", pos_score, neg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "fc71d165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hotel_sents = \". \".join(\n",
    "#     partner1_df['clean_hotel_name'].values) + \", \" + \". \".join(\n",
    "#      partner2_df['clean_hotel_name'].values) #+ \", \" + \". \".join(\n",
    "# #     examples_df['p1.clean_hotel_name'].values) + \", \" + \". \".join(\n",
    "# #     examples_df['p2.clean_hotel_name'].values) + \", \" + \". \".join(\n",
    "# #     examples_df['p2.clean_address'].values) + \", \" + \". \".join(\n",
    "# #     examples_df['p2.clean_address'].values) + \", \" + \". \".join(\n",
    "# #     partner1_df['clean_address'].values) + \", \" + \". \".join(\n",
    "# #     partner2_df['clean_address'].values)\n",
    "    \n",
    "# hotel_sents\n",
    "# with open('hotel_sents.txt', 'w') as f:\n",
    "#     f.write(hotel_sents)\n",
    "    \n",
    "# hotel_model = fasttext.train_unsupervised('hotel_sents.txt', model='skipgram', lr=0.01, dim=10, epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "aa2f85fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only very few without country_id so just drop them for now...\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "# # one hot encode country_id\n",
    "# s = pd.Series(all_countries[:10])\n",
    "# country_dummies = pd.get_dummies(s)\n",
    "# country_dummies.head()\n",
    "\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# ohe = OneHotEncoder()\n",
    "# ohe.fit(np.array(all_cities).reshape(-1, 1))\n",
    "# p1_encoded = ohe.transform(examples_df['p1.all_cities'].values.reshape(-1, 1)).toarray()\n",
    "# p2_encoded = ohe.transform(examples_df['p2.all_cities'].values.reshape(-1, 1)).toarray()\n",
    "# # test: examples_df['p1.country_code'][100], ohe.categories_[0][list(p1_encoded[100,:]).index(1)]\n",
    "# p1_df = pd.DataFrame(p1_encoded, columns=ohe.categories_[0])\n",
    "# p2_df = pd.DataFrame(p2_encoded, columns=ohe.categories_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "67206396",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p1_df = pd.DataFrame()\n",
    "p2_df = pd.DataFrame()\n",
    "final_partner1_df = pd.DataFrame()\n",
    "final_partner2_df = pd.DataFrame()\n",
    "\n",
    "list_of_cols_to_use = ['clean_hotel_name', \n",
    "                           'clean_address', \n",
    "                           'clean_postal_code',\n",
    "                           'city_name',\n",
    "                           'country_code']\n",
    "for col in list_of_cols_to_use:    \n",
    "    p1_df[col] = examples_df['p1.'+col]\n",
    "    p2_df[col] = examples_df['p1.'+col]\n",
    "    final_partner1_df[col] = partner1_df[col]\n",
    "    final_partner2_df[col] = partner2_df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5dddcedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate pos examples\n",
    "def get_min_postal_dist(s1, s2):\n",
    "    min_dist = 0.01\n",
    "    if type(s1) == float or type(s2) == float:\n",
    "        return min_dist\n",
    "#     if type(s1) != list:\n",
    "#         if s1 is pd.np.nan:\n",
    "#             return min_dist\n",
    "#         ifs1 = [s1]\n",
    "#     if type(s2) != list:\n",
    "#         if s2 is pd.np.nan:\n",
    "#             return min_dist\n",
    "#         s2 = [s2]\n",
    "    perms_p1 = [\"\".join(str(p)) for p in list(itertools.permutations(list(s1)))] + list(s1)\n",
    "    perms_p2 = [\"\".join(str(p)) for p in list(itertools.permutations(list(s2)))] + list(s2)\n",
    "    for p1 in perms_p1:\n",
    "        for p2 in perms_p2:\n",
    "            d = damerauLevenshtein(p1.lower(), p2.lower(), similarity=False) / np.min([len(p1), len(p2)])\n",
    "            if d < min_dist:\n",
    "                min_dist = d\n",
    "    return min_dist\n",
    "\n",
    "def calc_feature_vec(p1, p2, label):\n",
    "    features = []\n",
    "    features.append(\n",
    "        best_fuzz(p1['clean_hotel_name'], p2['clean_hotel_name'])\n",
    "    features.append(best_fuzz(p1['clean_address'], p2['clean_address']))\n",
    "    features.append(best_fuzz(p1['city_name'], p2['city_name']))\n",
    "    features.append(get_min_postal_dist(p1['clean_postal_code'], p2['clean_postal_code']))\n",
    "    features.append(label)\n",
    "    return features\n",
    "    \n",
    "    \n",
    "n = int(p1_df.shape[0]/2)\n",
    "pos = random.sample(range(0, p1_df.shape[0]-1), n)\n",
    "pos_features = []\n",
    "for idx in pos:\n",
    "    pos_features.append(calc_feature_vec(p1_df.loc[idx,:], p2_df.loc[idx,:], label=1))\n",
    "    \n",
    "neg_features = []\n",
    "for idx in pos:\n",
    "    new_idx = random.randint(0,p2_df.shape[0]-1)\n",
    "    neg_features.append(calc_feature_vec(p1_df.loc[idx,:], p2_df.loc[new_idx,:], label=0))\n",
    "    \n",
    "all_data = np.array(pos_features + neg_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3500e971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = all_data[:,:-1]\n",
    "y = all_data[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02eb219e",
   "metadata": {},
   "source": [
    "# ok time to train - actually stupid since I cleaned the data too much..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c9df60",
   "metadata": {},
   "source": [
    "it's not surprising the classifier is so good since we saw during sample eval on examples_df that data is seperated well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d9e6e449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[120,   0],\n",
       "       [  0, 129]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfa62f1",
   "metadata": {},
   "source": [
    "# split real data based on country_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0a6ec79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_final_partner1_df = {code: x for code, x in final_partner1_df.groupby('country_code')}\n",
    "list_final_partner2_df = {code: x for code, x in final_partner2_df.groupby('country_code')}\n",
    "\n",
    "# len(np.intersect1d(list(list_final_partner1_df), list(list_final_partner2_df)))/len(list(list_final_partner2_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "75a62dd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [40:05<00:00, 19.24s/it]\n"
     ]
    }
   ],
   "source": [
    "# this really needs to be parallel\n",
    "import pdb \n",
    "from tqdm import tqdm\n",
    "\n",
    "scores_dict = {}\n",
    "for code, p1_df in tqdm(list_final_partner1_df.items()):\n",
    "    p2_df = list_final_partner2_df[code]\n",
    "   # try:       \n",
    "    for r1_idx, r1 in p1_df.iterrows():\n",
    "        if r1_idx in scores_dict.keys():\n",
    "            print(r1_idx)\n",
    "        scores_dict[r1_idx] = {}\n",
    "        for r2_idx, r2 in p2_df.iterrows(): \n",
    "            s = 1 - np.mean(calc_feature_vec(r1, r2, -1)[:-1])\n",
    "#             f = calc_feature_vec(r1, r2, -1)[:-1]\n",
    "#             if f[1] == 0 or f[2] == 0:\n",
    "#                 s = 1\n",
    "#             else:\n",
    "#                 s = 1 - np.mean(f)\n",
    "            scores_dict[r1_idx][r2_idx] = s\n",
    "#     except Exception as e:\n",
    "#         print(code, e)\n",
    "#         pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "dd1580a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('scores_dict1.pkl', 'wb') as handle:\n",
    "#     pickle.dump(scores_dict, handle)\n",
    "\n",
    "with open('scores_dict.pkl', 'rb') as handle:\n",
    "    scores_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "73985e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def secondmax(arr):\n",
    "    sublist = [x for x in arr if x < max(arr)]\n",
    "    return np.max(sublist), np.argmax(sublist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e25b3e6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapping_dict = {}\n",
    "used_p1 = set()\n",
    "used_p2 = set()\n",
    "count1 = []\n",
    "count2 = []\n",
    "c = 0\n",
    "for key, val in scores_dict.items():\n",
    "    f = 0\n",
    "    v_scores = []\n",
    "    for v in val.values():\n",
    "        v_scores.append(v[0][1])\n",
    "    p2 = list(val)[np.argmax(v_scores)]\n",
    "    \n",
    "    p2_max_score = np.max(v_scores)\n",
    "#     if p2_max_score < 0.5:\n",
    "#         print(key, p2, p2_max_score)\n",
    "#         c+= 1\n",
    "    if key in used_p1:\n",
    "        f=1\n",
    "        count1.append(p1)\n",
    "    if p2 in used_p2:\n",
    "        f=1\n",
    "        count2.append(p2)\n",
    "    if f:\n",
    "        # Im just going to skip the problematic ones because of lack of time\n",
    "        continue\n",
    "    mapping_dict[p2] = (key, p2_max_score)\n",
    "    used_p1.add(key)\n",
    "    used_p2.add(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "c208f147",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9120, 2)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col1, col2 = [], []\n",
    "for key, (val, score) in mapping_dict.items():\n",
    "    # this should be experimented more but works ok from manual experiments\n",
    "    if score > 0.3:\n",
    "        if partner1_df.loc[val, 'country_code'] != partner2_df.loc[key, 'country_code']:\n",
    "            print(\"country_code sanity failed\")\n",
    "            break\n",
    "        col1.append(partner1_df.loc[val, 'key']) \n",
    "        col2.append(partner2_df.loc[key, 'key'])\n",
    "\n",
    "df = pd.DataFrame({'P1.key': col1, 'P2.key': col2})\n",
    "df.shape\n",
    "#df.to_csv(\"mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "8585bd55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>hotel_name</th>\n",
       "      <th>city_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>hotel_address</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>country_name</th>\n",
       "      <th>clean_postal_code</th>\n",
       "      <th>clean_address</th>\n",
       "      <th>clean_hotel_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3533</th>\n",
       "      <td>342FA6E48173B8396CAE2BE4CDEF862F</td>\n",
       "      <td>feng chia enjoy</td>\n",
       "      <td>taichung</td>\n",
       "      <td>TW</td>\n",
       "      <td>no.23, ln. 101, zhishan rd.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40745</td>\n",
       "      <td>taiwan (province of china)</td>\n",
       "      <td>[40745]</td>\n",
       "      <td>no 23 ln 101 zhishan</td>\n",
       "      <td>feng chia enjoy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9611</th>\n",
       "      <td>37CE703ED195AA8C71C91ED8EC17C7CE</td>\n",
       "      <td>feng chia enjoy</td>\n",
       "      <td>xitun</td>\n",
       "      <td>TW</td>\n",
       "      <td>no. 23, lane 101, zhishan road</td>\n",
       "      <td>1.0</td>\n",
       "      <td>407</td>\n",
       "      <td>taiwan (province of china)</td>\n",
       "      <td>[407]</td>\n",
       "      <td>no 23 lane 101 zhishan</td>\n",
       "      <td>feng chia enjoy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   key       hotel_name city_name  \\\n",
       "3533  342FA6E48173B8396CAE2BE4CDEF862F  feng chia enjoy  taichung   \n",
       "9611  37CE703ED195AA8C71C91ED8EC17C7CE  feng chia enjoy     xitun   \n",
       "\n",
       "     country_code                   hotel_address  star_rating postal_code  \\\n",
       "3533           TW     no.23, ln. 101, zhishan rd.          0.0       40745   \n",
       "9611           TW  no. 23, lane 101, zhishan road          1.0         407   \n",
       "\n",
       "                    country_name clean_postal_code           clean_address  \\\n",
       "3533  taiwan (province of china)           [40745]    no 23 ln 101 zhishan   \n",
       "9611  taiwan (province of china)             [407]  no 23 lane 101 zhishan   \n",
       "\n",
       "     clean_hotel_name  \n",
       "3533  feng chia enjoy  \n",
       "9611  feng chia enjoy  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity checks\n",
    "i = 7577\n",
    "pd.concat([partner1_df.loc[partner1_df.key == df[\"P1.key\"][i]], partner2_df.loc[partner2_df.key == df[\"P2.key\"][i]]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22b4a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad5c737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
